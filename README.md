Human Face Emotion Detection ðŸŽ­

Overview

This project focuses on building a Human Face Emotion Detection System that uses Convolutional Neural Networks (CNNs) to classify facial expressions into distinct emotion categories. The model is trained on grayscale images of faces and recognizes emotions like happiness, anger, sadness, and more. This project combines deep learning and image processing to develop an advanced emotion recognition model.

Features
Emotion classification into 8 categories: Anger, Contempt, Disgust, Fear, Happy, Neutral, Sad, Surprised.
Preprocessing pipeline for image resizing, normalization, and label encoding.
Data visualization using Matplotlib and Seaborn for insights on gender, age, and country distributions.
Robust CNN architecture with multiple convolutional and pooling layers for high accuracy.
Model evaluation using confusion matrix, classification report, and performance graphs.
Easily test the model on new images after saving and reloading.

Skills Gained
Deep Learning: Implementation of CNNs for image classification tasks.
Image Processing: Handling grayscale images, resizing, and preprocessing.
Data Analysis: Insights into datasets using visualizations.
Model Deployment: Save and reuse trained models for testing and predictions.

Dataset
The project uses the Facial Emotion Dataset, which contains labeled images of human faces annotated with emotion labels.

Future Enhancements
Integration with a live webcam feed for real-time emotion detection.
Deployment of the model as a web or mobile app.
Extending the model to work with RGB images for enhanced accuracy.
